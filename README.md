# BERT_SE

BERT_SE is a BERT model trained on a textual dataset in the area of software engineering.

BERT_SE passou por um processo de ajuste-fino, utilizando os algoritmos disponibilizados pelos autores do BERT (Devlin, et al., 2019). O dataset utilizado no ajuste-fino, denominado corp_SE, é composto por textos obtidos a partir de problemas e requisitos de usuário do Stackoverflow. Além disso, compóe o dataset, requisitos de software obtained from open-source projects & a textual corpus of 319.026 requirements from 16 large open-source projects in 9 repositories (Apache, Appcelerator, DuraSpace, Atlassian, Moodle, Lsstcorp, Mulesoft, Spring and Talendforge) (Choetkiertikul et al., 2018) and from others 22 open-source datasets (Dalpiaz, 2018).

Therefore, the corp_SE is composed of 456.500 texts, in this paper called sentences. Each sentence has an average length of 61 words. The vocabulary generated by the corp_SE is composed of 1.179.501 words.

It results and details of the evaluation are in the paper. 

